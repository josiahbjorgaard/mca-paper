{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1ece850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_from_disk\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../')\n",
    "import os\n",
    "os.environ[\"HF_DATASETS_CACHE\"]=\"/job_workspace/.cache/huggingface/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83421e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets = load_from_disk('/job_workspace/how2_all_proc_10p') #Just filtered Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba979312",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ab880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import setup_data\n",
    "datasets = setup_data('/job_workspace/how2_all_proc_10p', ds_frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b6b32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 50\n",
    "output_dirs={\n",
    "    'z90':'training_output_05_15_30_01_2024',\n",
    "    'm90':'training_output_01_09_30_01_2024',\n",
    "    'm90-2': 'training_output_05_40_30_01_2024_1',\n",
    "    'z50':'training_output_05_26_30_01_2024',\n",
    "    'm50':'training_output_05_34_30_01_2024',\n",
    "    'm50-2': 'training_output_07_10_30_01_2024',\n",
    "    'z30':'training_output_16_13_30_01_2024',\n",
    "    'm30': 'training_output_16_04_30_01_2024',\n",
    "    'z10':'training_output_16_22_30_01_2024_2',\n",
    "    'm10':'training_output_16_19_30_01_2024'\n",
    "}\n",
    "embeddings={\n",
    "    'z90':'training_output_04_15_31_01_2024',\n",
    "    'm90':'training_output_03_41_31_01_2024',\n",
    "    'm90-2': 'training_output_06_21_31_01_2024',\n",
    "    'z50':'training_output_04_47_31_01_2024',\n",
    "    'm50':'training_output_05_54_31_01_2024',\n",
    "    'm50-2': 'training_output_07_27_31_01_2024',\n",
    "    'z30':'training_output_09_09_31_01_2024',\n",
    "    'm30': 'training_output_08_01_31_01_2024',\n",
    "    'z10':'training_output_10_44_31_01_2024',\n",
    "    'm10':'training_output_09_35_31_01_2024'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60119c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD\n",
    "from torch import nn\n",
    "def compute_cosines(embedding, embeddings):\n",
    "    #for k,v in embeddings.items():\n",
    "    cos0 = torch.nn.CosineSimilarity(dim=1)\n",
    "    return cos0(embedding.unsqueeze(0).repeat(embeddings.shape[0],1), embeddings)\n",
    "def get_rank(x, indices):\n",
    "    vals = x[range(len(x)), indices]\n",
    "    return (x > vals[:, None]).long().sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "917ef7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test = 'm10'\n",
    "e=torch.load(f'../{embeddings[test]}/train_embeddings.pt')\n",
    "m=torch.load(f'../{embeddings[test]}/train_masks.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4702bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_metrics(embeddings, masks, modality, fusion=\"fusion\"):\n",
    "    c=list()\n",
    "    xc=list()\n",
    "    idx = list()\n",
    "    batch_size = 4096*2\n",
    "    for i in range(batch_size):\n",
    "        mx=m[modality][i]\n",
    "        if not mx:\n",
    "            pass\n",
    "        idx.append(i)\n",
    "        x=e[modality][i,:] #.shape\n",
    "        #xx=e['pt']\n",
    "        #xc.append(compute_recall(x,xx).topk(10))\n",
    "        y=e[fusion]#.shape\n",
    "        c.append(compute_cosines(x,y))\n",
    "        #print(c[i].topk(25))\n",
    "        #_=plt.hist(c.cpu(), bins=1000, log=True)\n",
    "    ranks = get_rank(torch.stack(c), torch.tensor(idx))\n",
    "    median_rank = ranks.median()\n",
    "    r1 = sum(ranks == 0)/len(ranks)\n",
    "    r5 = sum(ranks < 5)/len(ranks)\n",
    "    r10 = sum(ranks < 10)/len(ranks)\n",
    "    return median_rank, r1, r5, r10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf735ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z90-aud-[379, 0.0550537109375, 0.0723876953125, 0.074951171875]\n",
      "z90-en-[16, 0.0089111328125, 0.0247802734375, 0.03662109375]\n",
      "z90-pt-[15, 0.0096435546875, 0.027099609375, 0.0394287109375]\n",
      "z90-sm-[2465, 0.00390625, 0.016845703125, 0.03076171875]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacity of 79.33 GiB of which 732.44 MiB is free. Process 3116061 has 69.78 GiB memory in use. Process 187144 has 8.82 GiB memory in use. Of the allocated memory 7.45 GiB is allocated by PyTorch, and 909.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m header\u001b[38;5;241m.\u001b[39mappend(k)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k2 \u001b[38;5;129;01min\u001b[39;00m modalities:\n\u001b[0;32m---> 10\u001b[0m     x\u001b[38;5;241m=\u001b[39m[x\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrank_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk2\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     data[k2]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mx\n",
      "Cell \u001b[0;32mIn[15], line 18\u001b[0m, in \u001b[0;36mrank_metrics\u001b[0;34m(embeddings, masks, modality, fusion)\u001b[0m\n\u001b[1;32m     15\u001b[0m     c\u001b[38;5;241m.\u001b[39mappend(compute_cosines(x,y))\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#print(c[i].topk(25))\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#_=plt.hist(c.cpu(), bins=1000, log=True)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m ranks \u001b[38;5;241m=\u001b[39m \u001b[43mget_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m median_rank \u001b[38;5;241m=\u001b[39m ranks\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[1;32m     20\u001b[0m r1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(ranks \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(ranks)\n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36mget_rank\u001b[0;34m(x, indices)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_rank\u001b[39m(x, indices):\n\u001b[1;32m      8\u001b[0m     vals \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x)), indices]\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacity of 79.33 GiB of which 732.44 MiB is free. Process 3116061 has 69.78 GiB memory in use. Process 187144 has 8.82 GiB memory in use. Of the allocated memory 7.45 GiB is allocated by PyTorch, and 909.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "modalities = ['aud','en','pt','sm']\n",
    "data = defaultdict(list)\n",
    "header = []\n",
    "for k,v in embeddings.items():\n",
    "    e=torch.load(f'../{v}/eval_embeddings.pt')\n",
    "    m=torch.load(f'../{v}/eval_masks.pt')\n",
    "    header.append(k)\n",
    "    for k2 in modalities:\n",
    "        x=[x.cpu().item() for x in rank_metrics(e,m,k2)]\n",
    "        print(f\"{k}-{k2}-{x}\")\n",
    "        data[k2]+=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcbbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict2ltxtab(d: dict, bare=False, headrow = None):\n",
    "    if not bare:\n",
    "        print(r\"\\begin{center}\")\n",
    "        print(r\"\\begin{tabular}{|c|c|}\")\n",
    "        print(r\"\\hline\")\n",
    "    if headrow and len(headrow) >= 2:\n",
    "        print(headrow[0], \"&\", headrow[1], r\"\\\\\")\n",
    "        print(r\"\\hline\")\n",
    "    for k, v in d.items():\n",
    "        print(k, \"&\", v, r\"\\\\\")\n",
    "    if not bare:\n",
    "        print(r\"\\hline\")\n",
    "        print(r\"\\end{tabular}\")\n",
    "        print(r\"\\end{center}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "92a09dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1032.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ranks.float().cpu().median())\n",
    "_ = plt.hist(ranks.cpu(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61ae26bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos0 = torch.nn.CosineSimilarity(dim=1)\n",
    "output0 = cos0(torch.ones([3,10]), torch.ones([3,10]))\n",
    "output0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../training_output_03_41_31_01_2024/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_model\n",
    "from model import MFDOOM\n",
    "from encoders import MultimodalCollator\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.config import training_config, get_model_config\n",
    "output_dir = \"/efs-private/multimodal/training_output_01_35_20_01_2024\" #0.8 Doom\n",
    "#output_dir = \"/efs-private/multimodal/training_output_01_36_20_01_2024\" #0.3 Doom\n",
    "#output_dir = \"/efs-private/multimodal/training_output_01_38_20_01_2024\" #0.8 Zorro\n",
    "#output_dir = \"/efs-private/multimodal/training_output_01_37_20_01_2024\" #0.3 Zorro\n",
    "config = training_config(os.path.join(output_dir,'config.yaml'))\n",
    "model_config = get_model_config(config)\n",
    "model_config['batch_size']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e896ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "from importlib import reload\n",
    "reload(model)\n",
    "from model import MFDOOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_data_collator = MultimodalCollator(config.modality_config)\n",
    "#dataloader2 = DataLoader(dataset.with_format('torch'), shuffle=True, collate_fn=default_data_collator, batch_size=4,)\n",
    "dataloader = DataLoader(datasets['test'].with_format('torch'), \n",
    "                        shuffle=True, \n",
    "                        collate_fn=default_data_collator, \n",
    "                        batch_size=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = MFDOOM(**model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors.torch import load_model\n",
    "load_model(model,os.path.join(output_dir,'model.safetensors'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef043e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl=iter(dataloader)\n",
    "infer_model = model.eval()\n",
    "#batch = [next(dl) for x in range(4)]\n",
    "output = [infer_model(next(dl)) for _ in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b54243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_modes(batch, modes_to_zero):\n",
    "    for mode in modes_to_zero:\n",
    "        print(mode)\n",
    "        if mode == 'aud':\n",
    "            batch[mode]['values'] = torch.ones_like(batch[mode]['values'])*-10000\n",
    "        elif mode == 'vid':\n",
    "            batch[mode]['attention_mask']=torch.ones_like(batch[mode]['attention_mask'])\n",
    "        else:\n",
    "            batch[mode]['attention_mask']=torch.ones_like(batch[mode]['attention_mask'])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d7bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import random\n",
    "output=defaultdict(list)\n",
    "infer_model = model.eval()\n",
    "dl = iter(dataloader)\n",
    "#mode_sets = [('aud',),('sm',),('en',),('pt',),('vid',)]\n",
    "mode_sets = [('aud','sm',), ('vid','aud',), ('sm','en','pt',)]\n",
    "batches = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(4)):\n",
    "        batch = next(dl)\n",
    "        batches.append(batch)\n",
    "        #batch = {k: {k2: v2 for k2,v2 in v.items()} for k,v in batch.items()}\n",
    "        output[('baseline',)].append(infer_model(batch))\n",
    "        random.shuffle(mode_sets)\n",
    "        for modes in mode_sets:\n",
    "            mode_batch = copy.deepcopy(batch)\n",
    "            output[modes].append(infer_model(zero_modes(mode_batch,modes)))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686657b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor(outputs):\n",
    "    out_dict = {k:[] for k in outputs[0]}\n",
    "    for k in [\"losses\", \"loss\", \"modality_sample_mask\"]:\n",
    "        out_dict.pop(k, None)\n",
    "    for batch in outputs:\n",
    "        for key in out_dict.keys():\n",
    "            out_dict[key].append(batch[key])\n",
    "    print(out_dict.keys())\n",
    "    out_dict = {k:torch.cat(v) for k,v in out_dict.items()}\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b79d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_r = {k: refactor(v) for k,v in output.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a04ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[('baseline',)][0]['aud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be3ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cosines(output, output2=None, log=False, vmin=None, vmax=None, plot_diag=True):\n",
    "    cos = torch.nn.CosineSimilarity(dim=0)\n",
    "    mat_dict={}\n",
    "    for k,v in output.items():\n",
    "        l = v.shape[0]\n",
    "        mat_dict[k]=np.zeros([l,l])\n",
    "        v2 = output2[k] if output2 else output['fusion']\n",
    "        for i in range(l):\n",
    "            for j in range(l):\n",
    "                #print(f\"{i},{j},{cos(output.fusion[i],output.fusion[j])}\")\n",
    "                if log:\n",
    "                    mat_dict[k][i,j]=np.log10(cos(v[i],v2[j]))\n",
    "                else:\n",
    "                    mat_dict[k][i,j]=cos(v[i],v2[j])\n",
    "\n",
    "    f, ax = plt.subplots(len(mat_dict),2, figsize=(6,3*len(mat_dict)))\n",
    "    for i,(k,mat) in enumerate(mat_dict.items()):\n",
    "        #f, (ax1, ax2) = plt.subplots(1,2, figsize=(6,2))\n",
    "        #plt.figure(figsize=(2,2))\n",
    "        #ax1.title(k)\n",
    "        ax1 = ax[i,0]\n",
    "        im = ax1.imshow(mat, vmin=vmin, vmax=vmax)\n",
    "        ax1.set_ylabel(k)\n",
    "        f.colorbar(im,ax=ax1)\n",
    "        if plot_diag:\n",
    "            #plt.figure(figsize=(2,2))\n",
    "            #plt.title(f\"{k} diagonals\")\n",
    "            bins = np.linspace(0,1.0,100)\n",
    "            ax2 = ax[i,1]\n",
    "            ax2.hist(np.diagonal(mat), bins=bins, alpha=0.3,density=True)\n",
    "            ax2.hist(mat.flatten(), bins=bins, alpha=0.3, density=True)\n",
    "            ax2.set_ylim(0,50)\n",
    "            ax2.set_xlim(0,1.0)\n",
    "            ax2.annotate(str(np.mean((mat.sum(1)-np.diag(mat))/(mat.shape[1]-1))),\n",
    "                        [0.1, 0.1])\n",
    "            ax2.legend([\"diag\",\"all\"])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d555a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_r.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e03247",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = mode_sets[0]\n",
    "print(k)\n",
    "plot_cosines(output_r[('baseline',)],output_r[k],vmin=0.99999) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b018254",
   "metadata": {},
   "source": [
    "# Attention masking tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.pool_mask, aspect=100)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd256216",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.load('../batch.pt', map_location=torch.device('cpu'))\n",
    "p=torch.load('../padding_mask.pt', map_location=torch.device('cpu'))\n",
    "a = torch.load('../attn_mask.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3251059",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(p[0,:])\n",
    "plt.figure()\n",
    "plt.plot(p[1,:])\n",
    "plt.figure()\n",
    "plt.plot(p[4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef710f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.isnan().reshape((-1,t.shape[1]*t.shape[2]))\n",
    "      .shape)\n",
    "plt.imshow(torch.cat([t.isnan()[i,:,:] for i in range(8)], dim=1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c7c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "token_types = torch.tensor(list((\n",
    "    *((0,) * 1024),\n",
    "    *((1,) * 1024),\n",
    "    *((2,) * 1024),\n",
    "    *((3,) * 1024),\n",
    ")), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_types_attend_from = rearrange(token_types, 'i -> i 1')\n",
    "token_types_attend_to = rearrange(token_types, 'j -> 1 j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zorro_mask = token_types_attend_from == token_types_attend_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37900f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zorro_mask = zorro_mask | (token_types_attend_from == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2d622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_types\n",
    "floom_mask = [token_types != i for i in range(-1,3)]\n",
    "for idx, tokens in enumerate(floom_mask):\n",
    "    print(idx)\n",
    "    a = -256*4 + 256*idx\n",
    "    b = -256*4 + 256*(idx+1)-1\n",
    "    print(f\"{a}:{b}\")\n",
    "    tokens[-256*4:] = False\n",
    "    tokens[a:b]= True\n",
    "floom_mask = repeat(floom_mask, 'i j -> (i i2) j', i2=256)\n",
    "plt.imshow(floom_mask)#, aspect = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112c4de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "zorro_mask[token_types == 3] = floom_mask\n",
    "plt.imshow(zorro_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dce948",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(1,1,1)\n",
    "im = ax.imshow(attn_mask[3,:,:] * zorro_mask)\n",
    "labels = ['0','Modality 1','Modality 2','Modality 3','Fusion -1', 'Fusion 0', 'Fusion 1', 'Fusion 2','Global Tokens']\n",
    "ax.set_yticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.empty(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db5383",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b42e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_token_types = (0,1,2,3,3,3,3,4)\n",
    "return_token_types_tensor = torch.tensor(list(return_token_types))\n",
    "max_return_tokens = len(return_token_types)\n",
    "dim=512\n",
    "return_tokens = torch.nn.Parameter(torch.randn(max_return_tokens, dim))\n",
    "return_tokens = repeat(return_tokens, 'n d -> b n d', b=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8091a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_mask = rearrange(return_token_types_tensor, 'i -> i 1') == token_types_attend_to\n",
    "pool_mask = pool_mask | (rearrange(return_token_types_tensor, 'i -> i 1') == torch.ones_like(\n",
    "            token_types_attend_to, dtype=torch.long) * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pool_mask.to(torch.long), aspect=1000) #'auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "floom_pool_mask = torch.block_diag(torch.ones((1,256)), \n",
    "                              torch.ones((1,256)), \n",
    "                              torch.ones((1,256)), \n",
    "                              torch.ones((1,256)))\n",
    "print(token_types.shape)\n",
    "select_mask = (return_token_types_tensor == 3).unsqueeze(1) *(token_types == 3).unsqueeze(0)\n",
    "print(select_mask.shape)\n",
    "pool_mask[select_mask] = floom_pool_mask.to(torch.bool).flatten()\n",
    "#floom_mask = repeat(floom_mask, 'i j -> i j')\n",
    "ax = plt.subplot(1,1,1)\n",
    "im = ax.imshow(pool_mask, aspect=1000, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e82416",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((return_token_types_tensor == 3).unsqueeze(1) *\n",
    "           (token_types == 3).unsqueeze(0), aspect =1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f264b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pool_mask.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37eb5a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "padding_mask = repeat(padding, 'b j -> b i j', i=pool_mask.shape[0])\n",
    "print(padding_mask.shape)\n",
    "plt.imshow(padding_mask[0,:,:].squeeze(), aspect=1000)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72bf166",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_mask = pool_mask * padding_mask\n",
    "ax = plt.subplot(1,1,1)\n",
    "im = ax.imshow(pool_mask[0], aspect=1000, interpolation='none')\n",
    "#labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "labels = ['0','Modality 1','Modality 2','Modality 3','Fusion -1', 'Fusion 0', 'Fusion 1', 'Fusion 2','Global Tokens']\n",
    "ax.set_yticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9426b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=torch.tensor([[1,2],\n",
    "                [1,1]])\n",
    "k=torch.tensor([[1,1],\n",
    "                [2,1]])\n",
    "v=q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import einsum\n",
    "sim = einsum('i d, d j -> i j', q, k) #Standard mm multipy\n",
    "sim = einsum('i d, j d -> i j', q, k) #mm multiply with k transpose\n",
    "print(sim)\n",
    "#sim = sim.masked_fill(~attn_mask, -torch.finfo(sim.dtype).max)\n",
    "#attn = sim.softmax(dim=-1)\n",
    "attn = sim\n",
    "out = einsum('i j, j d -> i d', attn, v) #standard multiply with no tranpose\n",
    "print(out)\n",
    "### SO COLUMNS SHOULD BE -inf for the mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044571c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7913036",
   "metadata": {},
   "source": [
    "# Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "import os\n",
    "os.environ['HF_DATASETS_CACHE']='/shared/.cache/hugginface/dataset'\n",
    "datasets = [\n",
    "   'ad98d3cd-26fb-4ee3-99c9-8a2ab085e737_combined_all',\n",
    "    'fcaa53cd-ba57-4bfe-af9c-eaa958f95c1a_combined_all',\n",
    "    'cc95ff89-2e68-4a08-a234-480eca21ce79_combined_all',\n",
    "    'fde199d2-a841-4ed1-aa65-b9e0af8969b1_combined_all'\n",
    "]\n",
    "root = '/shared/'\n",
    "loaded_datasets=[]\n",
    "for dataset in datasets:\n",
    "    loaded_datasets.append(load_from_disk(os.path.join(root,dataset)))\n",
    "all_datasets=concatenate_datasets(loaded_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0df3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset = all_datasets.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e792c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shuffled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1905102",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset.save_to_disk(os.path.join(root,'dataset3M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562633f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bc6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d662bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[torch.tensor([0,4,9])]=torch.tensor([1,2,3], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decbe11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2951af",
   "metadata": {},
   "outputs": [],
   "source": [
    "    f, ax= plt.subplots(4,2, figsize=(6,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "!ls /shared\n",
    "dataset = datasets.load_from_disk('/shared/how2_all_proc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d74460",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]['vid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cf764",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #if plot_diag:\n",
    "        \"\"\"\n",
    "        plt.figure()\n",
    "        plt.title(\"diagonals\")\n",
    "        diags = {k:np.diagonal(mat) for k,mat in mat_dict.items()}\n",
    "        plt.hist(diags.values(), bins=20)\n",
    "        plt.legend(diags.keys())\n",
    "        plt.ylabel('Number of Batches')\n",
    "        plt.xlabel('Diag Cosine Similarity')\n",
    "        plt.figure()\n",
    "        plt.title(\"diagonals\")\n",
    "        diags = {k:np.diagonal(mat) for k,mat in mat_dict.items()}\n",
    "        diags_norm = {k:np.diagonal(mat)-np.mean(mat_dict[k]) for k, mat in mat_dict.items()}\n",
    "        plt.hist(diags_norm.values(), bins=20)\n",
    "        plt.legend(diags_norm.keys())\n",
    "        plt.ylabel('Number of Batches')\n",
    "        plt.xlabel('%Cosine Similarity Change from Mean of Diagonal')\n",
    "        diags = {k:np.diagonal(mat) for k,mat in mat_dict.items()}\n",
    "        diags_norm = {k:np.diagonal(mat)-np.mean(mat_dict[k]) for k, mat in mat_dict.items()}\n",
    "        plt.hist(diags_norm.values(), bins=20)\n",
    "        plt.legend(diags_norm.keys())\n",
    "        plt.ylabel('Number of Batches')\n",
    "        plt.xlabel('%Cosine Similarity Change from Mean of Diagonal')        \n",
    "        \"\"\"\n",
    "        #plt.figure()\n",
    "        #plt.title(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7551ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[0,1,1,1],[0,1,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25875653",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randperm(10)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d8584",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.swapaxes(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [torch.Tensor([0.3]), torch.Tensor([1.3]), torch.Tensor([2.3]), torch.Tensor([np.nan])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e216ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f35ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=~y.isnan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014bc52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=torch.sum(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(y[z])/w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99932b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ranks.float().cpu().median())\n",
    "_ = plt.hist(ranks.cpu(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acc24349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos0 = torch.nn.CosineSimilarity(dim=1)\n",
    "output0 = cos0(torch.ones([3,10]), torch.ones([3,10]))\n",
    "output0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../training_output_03_41_31_01_2024/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f29c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_model\n",
    "from model import MFDOOM\n",
    "from encoders import MultimodalCollator\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.config import training_config, get_model_config\n",
    "output_dir = \"/efs-private/multimodal/training_output_01_35_20_01_2024\" #0.8 Doom\n",
    "#output_dir = \"/efs-private/multimodal/training_output_01_36_20_01_2024\" #0.3 Doom\n",
    "#output_dir = \"/efs-private/multimodal/training_output_01_38_20_01_2024\" #0.8 Zorro\n",
    "#output_dir = \"/efs-private/multimodal/training_output_01_37_20_01_2024\" #0.3 Zorro\n",
    "config = training_config(os.path.join(output_dir,'config.yaml'))\n",
    "model_config = get_model_config(config)\n",
    "model_config['batch_size']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00005d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "from importlib import reload\n",
    "reload(model)\n",
    "from model import MFDOOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b8c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_data_collator = MultimodalCollator(config.modality_config)\n",
    "#dataloader2 = DataLoader(dataset.with_format('torch'), shuffle=True, collate_fn=default_data_collator, batch_size=4,)\n",
    "dataloader = DataLoader(datasets['test'].with_format('torch'), \n",
    "                        shuffle=True, \n",
    "                        collate_fn=default_data_collator, \n",
    "                        batch_size=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c32f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = MFDOOM(**model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors.torch import load_model\n",
    "load_model(model,os.path.join(output_dir,'model.safetensors'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef58c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl=iter(dataloader)\n",
    "infer_model = model.eval()\n",
    "#batch = [next(dl) for x in range(4)]\n",
    "output = [infer_model(next(dl)) for _ in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac5fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_modes(batch, modes_to_zero):\n",
    "    for mode in modes_to_zero:\n",
    "        print(mode)\n",
    "        if mode == 'aud':\n",
    "            batch[mode]['values'] = torch.ones_like(batch[mode]['values'])*-10000\n",
    "        elif mode == 'vid':\n",
    "            batch[mode]['attention_mask']=torch.ones_like(batch[mode]['attention_mask'])\n",
    "        else:\n",
    "            batch[mode]['attention_mask']=torch.ones_like(batch[mode]['attention_mask'])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85c3b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import random\n",
    "output=defaultdict(list)\n",
    "infer_model = model.eval()\n",
    "dl = iter(dataloader)\n",
    "#mode_sets = [('aud',),('sm',),('en',),('pt',),('vid',)]\n",
    "mode_sets = [('aud','sm',), ('vid','aud',), ('sm','en','pt',)]\n",
    "batches = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(4)):\n",
    "        batch = next(dl)\n",
    "        batches.append(batch)\n",
    "        #batch = {k: {k2: v2 for k2,v2 in v.items()} for k,v in batch.items()}\n",
    "        output[('baseline',)].append(infer_model(batch))\n",
    "        random.shuffle(mode_sets)\n",
    "        for modes in mode_sets:\n",
    "            mode_batch = copy.deepcopy(batch)\n",
    "            output[modes].append(infer_model(zero_modes(mode_batch,modes)))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df5367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor(outputs):\n",
    "    out_dict = {k:[] for k in outputs[0]}\n",
    "    for k in [\"losses\", \"loss\", \"modality_sample_mask\"]:\n",
    "        out_dict.pop(k, None)\n",
    "    for batch in outputs:\n",
    "        for key in out_dict.keys():\n",
    "            out_dict[key].append(batch[key])\n",
    "    print(out_dict.keys())\n",
    "    out_dict = {k:torch.cat(v) for k,v in out_dict.items()}\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c775c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_r = {k: refactor(v) for k,v in output.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[('baseline',)][0]['aud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fad6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cosines(output, output2=None, log=False, vmin=None, vmax=None, plot_diag=True):\n",
    "    cos = torch.nn.CosineSimilarity(dim=0)\n",
    "    mat_dict={}\n",
    "    for k,v in output.items():\n",
    "        l = v.shape[0]\n",
    "        mat_dict[k]=np.zeros([l,l])\n",
    "        v2 = output2[k] if output2 else output['fusion']\n",
    "        for i in range(l):\n",
    "            for j in range(l):\n",
    "                #print(f\"{i},{j},{cos(output.fusion[i],output.fusion[j])}\")\n",
    "                if log:\n",
    "                    mat_dict[k][i,j]=np.log10(cos(v[i],v2[j]))\n",
    "                else:\n",
    "                    mat_dict[k][i,j]=cos(v[i],v2[j])\n",
    "\n",
    "    f, ax = plt.subplots(len(mat_dict),2, figsize=(6,3*len(mat_dict)))\n",
    "    for i,(k,mat) in enumerate(mat_dict.items()):\n",
    "        #f, (ax1, ax2) = plt.subplots(1,2, figsize=(6,2))\n",
    "        #plt.figure(figsize=(2,2))\n",
    "        #ax1.title(k)\n",
    "        ax1 = ax[i,0]\n",
    "        im = ax1.imshow(mat, vmin=vmin, vmax=vmax)\n",
    "        ax1.set_ylabel(k)\n",
    "        f.colorbar(im,ax=ax1)\n",
    "        if plot_diag:\n",
    "            #plt.figure(figsize=(2,2))\n",
    "            #plt.title(f\"{k} diagonals\")\n",
    "            bins = np.linspace(0,1.0,100)\n",
    "            ax2 = ax[i,1]\n",
    "            ax2.hist(np.diagonal(mat), bins=bins, alpha=0.3,density=True)\n",
    "            ax2.hist(mat.flatten(), bins=bins, alpha=0.3, density=True)\n",
    "            ax2.set_ylim(0,50)\n",
    "            ax2.set_xlim(0,1.0)\n",
    "            ax2.annotate(str(np.mean((mat.sum(1)-np.diag(mat))/(mat.shape[1]-1))),\n",
    "                        [0.1, 0.1])\n",
    "            ax2.legend([\"diag\",\"all\"])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_r.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = mode_sets[0]\n",
    "print(k)\n",
    "plot_cosines(output_r[('baseline',)],output_r[k],vmin=0.99999) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805d91dc",
   "metadata": {},
   "source": [
    "# Attention masking tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.pool_mask, aspect=100)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7fc8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.load('../batch.pt', map_location=torch.device('cpu'))\n",
    "p=torch.load('../padding_mask.pt', map_location=torch.device('cpu'))\n",
    "a = torch.load('../attn_mask.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(p[0,:])\n",
    "plt.figure()\n",
    "plt.plot(p[1,:])\n",
    "plt.figure()\n",
    "plt.plot(p[4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f77d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.isnan().reshape((-1,t.shape[1]*t.shape[2]))\n",
    "      .shape)\n",
    "plt.imshow(torch.cat([t.isnan()[i,:,:] for i in range(8)], dim=1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "token_types = torch.tensor(list((\n",
    "    *((0,) * 1024),\n",
    "    *((1,) * 1024),\n",
    "    *((2,) * 1024),\n",
    "    *((3,) * 1024),\n",
    ")), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dbaaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_types_attend_from = rearrange(token_types, 'i -> i 1')\n",
    "token_types_attend_to = rearrange(token_types, 'j -> 1 j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3fb4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "zorro_mask = token_types_attend_from == token_types_attend_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac66da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zorro_mask = zorro_mask | (token_types_attend_from == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e865b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_types\n",
    "floom_mask = [token_types != i for i in range(-1,3)]\n",
    "for idx, tokens in enumerate(floom_mask):\n",
    "    print(idx)\n",
    "    a = -256*4 + 256*idx\n",
    "    b = -256*4 + 256*(idx+1)-1\n",
    "    print(f\"{a}:{b}\")\n",
    "    tokens[-256*4:] = False\n",
    "    tokens[a:b]= True\n",
    "floom_mask = repeat(floom_mask, 'i j -> (i i2) j', i2=256)\n",
    "plt.imshow(floom_mask)#, aspect = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4cd737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "zorro_mask[token_types == 3] = floom_mask\n",
    "plt.imshow(zorro_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7403f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(1,1,1)\n",
    "im = ax.imshow(attn_mask[3,:,:] * zorro_mask)\n",
    "labels = ['0','Modality 1','Modality 2','Modality 3','Fusion -1', 'Fusion 0', 'Fusion 1', 'Fusion 2','Global Tokens']\n",
    "ax.set_yticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe8365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.empty(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687cf0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf28b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_token_types = (0,1,2,3,3,3,3,4)\n",
    "return_token_types_tensor = torch.tensor(list(return_token_types))\n",
    "max_return_tokens = len(return_token_types)\n",
    "dim=512\n",
    "return_tokens = torch.nn.Parameter(torch.randn(max_return_tokens, dim))\n",
    "return_tokens = repeat(return_tokens, 'n d -> b n d', b=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afe937",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_mask = rearrange(return_token_types_tensor, 'i -> i 1') == token_types_attend_to\n",
    "pool_mask = pool_mask | (rearrange(return_token_types_tensor, 'i -> i 1') == torch.ones_like(\n",
    "            token_types_attend_to, dtype=torch.long) * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb3155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pool_mask.to(torch.long), aspect=1000) #'auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02489cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "floom_pool_mask = torch.block_diag(torch.ones((1,256)), \n",
    "                              torch.ones((1,256)), \n",
    "                              torch.ones((1,256)), \n",
    "                              torch.ones((1,256)))\n",
    "print(token_types.shape)\n",
    "select_mask = (return_token_types_tensor == 3).unsqueeze(1) *(token_types == 3).unsqueeze(0)\n",
    "print(select_mask.shape)\n",
    "pool_mask[select_mask] = floom_pool_mask.to(torch.bool).flatten()\n",
    "#floom_mask = repeat(floom_mask, 'i j -> i j')\n",
    "ax = plt.subplot(1,1,1)\n",
    "im = ax.imshow(pool_mask, aspect=1000, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((return_token_types_tensor == 3).unsqueeze(1) *\n",
    "           (token_types == 3).unsqueeze(0), aspect =1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pool_mask.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa81739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "padding_mask = repeat(padding, 'b j -> b i j', i=pool_mask.shape[0])\n",
    "print(padding_mask.shape)\n",
    "plt.imshow(padding_mask[0,:,:].squeeze(), aspect=1000)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_mask = pool_mask * padding_mask\n",
    "ax = plt.subplot(1,1,1)\n",
    "im = ax.imshow(pool_mask[0], aspect=1000, interpolation='none')\n",
    "#labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "labels = ['0','Modality 1','Modality 2','Modality 3','Fusion -1', 'Fusion 0', 'Fusion 1', 'Fusion 2','Global Tokens']\n",
    "ax.set_yticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfcd9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=torch.tensor([[1,2],\n",
    "                [1,1]])\n",
    "k=torch.tensor([[1,1],\n",
    "                [2,1]])\n",
    "v=q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cfe5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import einsum\n",
    "sim = einsum('i d, d j -> i j', q, k) #Standard mm multipy\n",
    "sim = einsum('i d, j d -> i j', q, k) #mm multiply with k transpose\n",
    "print(sim)\n",
    "#sim = sim.masked_fill(~attn_mask, -torch.finfo(sim.dtype).max)\n",
    "#attn = sim.softmax(dim=-1)\n",
    "attn = sim\n",
    "out = einsum('i j, j d -> i d', attn, v) #standard multiply with no tranpose\n",
    "print(out)\n",
    "### SO COLUMNS SHOULD BE -inf for the mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b41214",
   "metadata": {},
   "source": [
    "# Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d248fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "import os\n",
    "os.environ['HF_DATASETS_CACHE']='/shared/.cache/hugginface/dataset'\n",
    "datasets = [\n",
    "   'ad98d3cd-26fb-4ee3-99c9-8a2ab085e737_combined_all',\n",
    "    'fcaa53cd-ba57-4bfe-af9c-eaa958f95c1a_combined_all',\n",
    "    'cc95ff89-2e68-4a08-a234-480eca21ce79_combined_all',\n",
    "    'fde199d2-a841-4ed1-aa65-b9e0af8969b1_combined_all'\n",
    "]\n",
    "root = '/shared/'\n",
    "loaded_datasets=[]\n",
    "for dataset in datasets:\n",
    "    loaded_datasets.append(load_from_disk(os.path.join(root,dataset)))\n",
    "all_datasets=concatenate_datasets(loaded_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset = all_datasets.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1101e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shuffled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset.save_to_disk(os.path.join(root,'dataset3M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f80b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[torch.tensor([0,4,9])]=torch.tensor([1,2,3], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ec5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e056ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "    f, ax= plt.subplots(4,2, figsize=(6,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb983ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "!ls /shared\n",
    "dataset = datasets.load_from_disk('/shared/how2_all_proc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6dfb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]['vid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee2067",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #if plot_diag:\n",
    "        \"\"\"\n",
    "        plt.figure()\n",
    "        plt.title(\"diagonals\")\n",
    "        diags = {k:np.diagonal(mat) for k,mat in mat_dict.items()}\n",
    "        plt.hist(diags.values(), bins=20)\n",
    "        plt.legend(diags.keys())\n",
    "        plt.ylabel('Number of Batches')\n",
    "        plt.xlabel('Diag Cosine Similarity')\n",
    "        plt.figure()\n",
    "        plt.title(\"diagonals\")\n",
    "        diags = {k:np.diagonal(mat) for k,mat in mat_dict.items()}\n",
    "        diags_norm = {k:np.diagonal(mat)-np.mean(mat_dict[k]) for k, mat in mat_dict.items()}\n",
    "        plt.hist(diags_norm.values(), bins=20)\n",
    "        plt.legend(diags_norm.keys())\n",
    "        plt.ylabel('Number of Batches')\n",
    "        plt.xlabel('%Cosine Similarity Change from Mean of Diagonal')\n",
    "        diags = {k:np.diagonal(mat) for k,mat in mat_dict.items()}\n",
    "        diags_norm = {k:np.diagonal(mat)-np.mean(mat_dict[k]) for k, mat in mat_dict.items()}\n",
    "        plt.hist(diags_norm.values(), bins=20)\n",
    "        plt.legend(diags_norm.keys())\n",
    "        plt.ylabel('Number of Batches')\n",
    "        plt.xlabel('%Cosine Similarity Change from Mean of Diagonal')        \n",
    "        \"\"\"\n",
    "        #plt.figure()\n",
    "        #plt.title(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bcec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[0,1,1,1],[0,1,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randperm(10)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295db166",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.swapaxes(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309548f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [torch.Tensor([0.3]), torch.Tensor([1.3]), torch.Tensor([2.3]), torch.Tensor([np.nan])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=~y.isnan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=torch.sum(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7155f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(y[z])/w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c91083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e578b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
