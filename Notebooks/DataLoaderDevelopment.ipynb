{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f87f16",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'encoders'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_from_disk\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mencoders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BioZorroCollator\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'encoders'"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import DataCollatorWithPadding\n",
    "from encoders import BioZorroCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7611a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_protein_mrna_genes  pbmc_protein.h5ad\r\n",
      "pbmc_gene.h5ad\t\t     pbmc_w3_teaseq.h5mu\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data\n",
    "ds = load_from_disk('../data/filtered_protein_mrna_genes').with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1125dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import pad\n",
    "from torch import Tensor\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class BioZorroCollator:\n",
    "    def __init__(self, pad_token=0, pad_len=2048):\n",
    "        self.pad_token = pad_token\n",
    "        self.pad_len=pad_len\n",
    "    def __call__(self, data):#(2)\n",
    "        collated_data = {k:list() for k in data[0].keys()}\n",
    "        for d in data:\n",
    "            for k,v in d.items():\n",
    "                length = v.shape[-1]\n",
    "                padded_v = pad(v, (0,self.pad_len-length), mode='constant', value=self.pad_token)\n",
    "                collated_data[k].append(padded_v)\n",
    "        for k,v in collated_data.items():\n",
    "            collated_data[k]=torch.stack(v)\n",
    "        return collated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "665c26c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "        ds, shuffle=True, collate_fn=BioZorroCollator(), batch_size=16,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d27bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89649\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2fd6246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_index': tensor([[ 9, 26, 46,  ...,  0,  0,  0]]), 'spliced_index': tensor([[  9,  46, 275,  ...,   0,   0,   0]]), 'unspliced_index': tensor([[ 26, 136, 196,  ...,   0,   0,   0]]), 'ambiguous_index': tensor([[132, 304, 397,  ...,   0,   0,   0]]), 'total_data': tensor([[1., 1., 1.,  ..., 0., 0., 0.]]), 'spliced_data': tensor([[1., 1., 1.,  ..., 0., 0., 0.]]), 'unspliced_data': tensor([[1., 1., 1.,  ..., 0., 0., 0.]]), 'ambiguous_data': tensor([[1., 1., 1.,  ..., 0., 0., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "#from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.functional import pad\n",
    "data = next(iter(train_dataloader))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ed1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import muon as mu\n",
    "# Change directory to the root folder of the repository\n",
    "import os\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "890f36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/efs-private/st_perceiver\"\n",
    "mdata = mu.read(f\"{data_dir}/pbmc_w3_teaseq.h5mu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9431d1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArrayView(5805)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mdata[:,1].mod['rna'].X == mdata[:,1].mod['rna'].X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "878842d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([0.0]).to(\"cpu\")\n",
    "#Maybe one day these will work, but currently they aren't directly compatible with mudata object\n",
    "\n",
    "#from anndata.experimental.multi_files import AnnCollection\n",
    "#from anndata.experimental.pytorch import AnnLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad750c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import csr_matrix\n",
    "import anndata\n",
    "def sparse_csr_to_tensor(csr:csr_matrix):\n",
    "    \"\"\"\n",
    "    Transform scipy csr matrix to pytorch sparse tensor\n",
    "    \"\"\"\n",
    "\n",
    "    values = csr.data\n",
    "    indices = np.vstack(csr.nonzero())\n",
    "    shape = csr.shape\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    s = torch.Size(shape)\n",
    "\n",
    "    return torch.sparse.FloatTensor(i, v, s)\n",
    "    \n",
    "def sparse_batch_collate(batch:list):\n",
    "    \"\"\"\n",
    "    Collate function to transform anndata csr view to pytorch sparse tensor\n",
    "    \"\"\"\n",
    "    if type(batch[0]['atac'].X) == anndata._core.views.SparseCSRView:\n",
    "        atac_batch = sparse_csr_to_tensor(np.vstack([x['atac'].X for x in batch]))\n",
    "    else:\n",
    "        atac_batch = torch.FloatTensor(np.vstack([x['atac'].X for x in batch]))\n",
    "\n",
    "    if type(batch[0]['rna'].X) == anndata._core.views.SparseCSRView:\n",
    "        rna_batch = sparse_csr_to_tensor(np.vstack([x['rna'].X for x in batch]))\n",
    "    else:\n",
    "        rna_batch = torch.FloatTensor(np.vstack([x['rna'].X for x in batch]))\n",
    "    \n",
    "    if type(batch[0]['prot'].X) == anndata._core.views.SparseCSRView:\n",
    "        prot_batch = sparse_csr_to_tensor(np.vstack([x['prot'].X for x in batch]))\n",
    "    else:\n",
    "        prot_batch = torch.FloatTensor(np.vstack([x['prot'].X for x in batch]))\n",
    "\n",
    "    return atac_batch, rna_batch, prot_batch\n",
    "\n",
    "\n",
    "loader = DataLoader(\n",
    "    mdata,\n",
    "    batch_size=10,\n",
    "    collate_fn = sparse_batch_collate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bf321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aa4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(batch[0]['atac'].X) == anndata._core.views.SparseCSRView:\n",
    "        atac_batch = sparse_csr_to_tensor(np.vstack([x['atac'].X for x in batch]))\n",
    "    else:\n",
    "        atac_batch = torch.FloatTensor(np.vstack([x['atac'].X for x in batch]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933492f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/miniconda3/envs/stp/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/shared/miniconda3/envs/stp/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/shared/miniconda3/envs/stp/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/shared/miniconda3/envs/stp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/shared/miniconda3/envs/stp/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/efs-private/st_perceiver')\n",
    "from biozorromodel import BioZorro, TokenTypes as T\n",
    "from mudataloader import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be20ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BioZorro(\n",
    "                        512, #dim,\n",
    "                        6, #depth,\n",
    "                        96162, #16381, #rna_input_dim,\n",
    "                        16381, #96162, #atac_input_dim,\n",
    "                        dim_head = 64,\n",
    "                        heads = 8,\n",
    "                        ff_mult = 4,\n",
    "                        num_fusion_tokens = 16,\n",
    "                        return_token_types = (\n",
    "                            T.RNA,\n",
    "                            T.FUSION,\n",
    "                            T.GLOBAL,\n",
    "                            T.ATAC,\n",
    "                            )\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "565cefb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader('/efs-private/st_perceiver/pbmc_w3_teaseq.h5mu', batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56a21d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([1024, 96162])\n"
     ]
    }
   ],
   "source": [
    "loader = iter(dataloader)\n",
    "print(len(next(loader)))\n",
    "print(next(loader)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f495e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna, atac, prot = next(loader)\n",
    "res = model(rna=rna, atac=atac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a775c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmultimodal.modules.losses.contrastive_loss_with_temperature import ContrastiveLossWithTemperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9dbcc8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(24.6985, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna, atac, prot = next(loader)\n",
    "res = model(rna=rna, atac=atac)\n",
    "print(res[:,0,:].squeeze().shape)\n",
    "loss = ContrastiveLossWithTemperature()\n",
    "loss(res[:,0,:].squeeze(), res[:,3,:].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9122ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')\n",
    "rna, atac, prot = next(loader)\n",
    "res = model(rna=rna.to('cuda'), atac=atac.to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ad2caa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebooks\t  encoders.py\t   neuron_utils.py  run_trn.slurm\r\n",
      "biozorromodel.py  env.yaml\t   run_trn.py\t    train.py\r\n",
      "data\t\t  mudataloader.py  run_trn.sh\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09760f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001)\n",
    "num_training_steps = epochs * len(train_dl)\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "print(\"Start training: {}\".format(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())))\n",
    "## Start model training and defining the training loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_device_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.update(1)\n",
    "    print(f\"Epoch {epoch}: loss: {loss.detach()}\")\n",
    "        #\n",
    "    #if xm.is_master_ordinal(local=False):\n",
    "    wandb.log({\"epoch_loss\":loss.detach().to(\"cpu\")})\n",
    "\n",
    "logger.info(\"End training: {}\".format(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe433e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work39",
   "language": "python",
   "name": "work39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
